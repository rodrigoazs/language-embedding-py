{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a6c15b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27a3b151e30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.data import get_tokenizer\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "498fb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(corpora):\n",
    "    tokens = set()\n",
    "    tokenizer = get_tokenizer(None)\n",
    "    for line in corpora:\n",
    "        words = tokenizer(line)\n",
    "        for word in words:\n",
    "            for token in word:\n",
    "                tokens.add(token)\n",
    "    v1 = vocab(OrderedDict([(token, 1) for token in tokens]), specials=[\"<end>\", \"<pad>\"])\n",
    "    return v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "977690c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = \"\"\"Perda de pontos no futebol por racismo de torcedores ainda é realidade distante\n",
    "Brasil é o único país entre as principais ligas a prever a punição esportiva, que ainda não foi efetivamente aplicada\n",
    "Compartilhar nas redes sociais \"Tostão: Existe uma inversão no aprendizado esportivo\"\n",
    "Crianças precisam se divertir com a bola antes de aprender técnica e regras\n",
    "Compartilhar nas redes sociais \"Financial Times: Netflix fecha acordo de R$ 24,7 bilhões para transmitir luta livre nos EUA\"\n",
    "Netflix fecha acordo de R$ 24,7 bilhões para transmitir luta livre nos EUA\n",
    "Serviço de streaming exibirá a atração a partir de 2025 como parte de um acordo de dez anos\n",
    "Compartilhar nas redes sociais \"Futebol Internacional: Udinese fará jogo com portões fechados como punição por insultos a Maignan\"\n",
    "Udinese fará jogo com portões fechados como punição por insultos a Maignan\n",
    "Goleiro francês Mike Maignan, do Milan, foi alvo de insultos por parte de torcedores do time de Udine\n",
    "Compartilhar nas redes sociais \"Esporte: Corinthians e Cruzeiro disputam título da Copinha na Neo Química Arena\"\n",
    "Corinthians e Cruzeiro disputam título da Copinha na Neo Química Arena\n",
    "Partida decisiva acontece nesta quinta-feira (25), aniversário de São Paulo\n",
    "Compartilhar nas redes sociais \"Como É Que É?: Bets: por que apostas online viraram um fenômeno no Brasil?\"\n",
    "Bets: por que apostas online viraram um fenômeno no Brasil?\n",
    "Isabella Faria conversa com João Gabriel às 18h, ao vivo\n",
    "Compartilhar nas redes sociais \"O Mundo É uma Bola: Os campeões da preferência e da resistência\"\n",
    "Bruno Fernandes, do Manchester United, esteve em campo 76 vezes em 2023, cinco a mais que Gustavo Gómez, do Palmeiras, e Rodrygo, do Real Madrid\n",
    "Compartilhar nas redes sociais \"Esporte: Gigi Riva, lenda do futebol italiano, morre aos 79 anos\"\n",
    "Gigi Riva, lenda do futebol italiano, morre aos 79 anos\n",
    "Jogador foi campeão europeu em 1968 e vice-campeão mundial em 1970\n",
    "Compartilhar nas redes sociais \"Sandro Macedo: O efervescente mercadão de janeiro no futebol\"\n",
    "Janela de transferências dá a impressão de que clubes brasilianos são mais opulentos do que realmente são\n",
    "Compartilhar nas redes sociais \"Esporte: Equipe brasileira de curling vence pela primeira vez nas Olimpíadas de Inverno\"\n",
    "Equipe brasileira de curling vence pela primeira vez nas Olimpíadas de Inverno\n",
    "Modalidade é conhecida pelo uso de uma espécie de vassoura para deixar o gelo mais liso\n",
    "Compartilhar nas redes sociais \"Futebol Internacional: Presidente da Fifa defende derrota automática em casos de racismo nos estádios\"\n",
    "Presidente da Fifa defende derrota automática em casos de racismo nos estádios\n",
    "Manifestações contra jogadores negros ocorreram na Itália e na Inglaterra no sábado\n",
    "Compartilhar nas redes sociais \"Café da Manhã: Podcast discute a regulamentação e o impacto das apostas esportivas online\"\n",
    "Podcast discute a regulamentação e o impacto das apostas esportivas online\n",
    "Bets chegam a 15% da população, segundo o Datafolha; governo mira arrecadação, e especialistas alertam para riscos\n",
    "Compartilhar nas redes sociais \"Campeonato Paulista: Romero marca de voleio, e Corinthians estreia com vitória no Paulista\"\n",
    "Romero marca de voleio, e Corinthians estreia com vitória no Paulista\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5128664",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = get_vocab(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80903d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, char_num_embeddings=10, char_embedding_dim=5, word_embedding_dim=2, word_chars_size=5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.char_num_embeddings = char_num_embeddings\n",
    "        self.char_embedding_dim = char_embedding_dim\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "        self.word_chars_size = word_chars_size\n",
    "        \n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Embedding(char_num_embeddings, char_embedding_dim, max_norm=True)\n",
    "        )\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=(3, char_embedding_dim), padding=(2, 0)),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 16, kernel_size=(3, 1), padding=(2, 0)),\n",
    "            nn.Flatten(1, 3),\n",
    "            nn.Linear((self.word_chars_size + 4) * 16, word_embedding_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x), 1, self.word_chars_size)\n",
    "        return self.encoder(self.embedding(x))\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, char_num_embeddings=10, char_embedding_dim=5, word_embedding_dim=2, word_chars_size=5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.char_num_embeddings = char_num_embeddings\n",
    "        self.char_embedding_dim = char_embedding_dim\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "        self.word_chars_size = word_chars_size\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(word_embedding_dim, (self.word_chars_size + 4) * 16),\n",
    "            nn.Unflatten(1, (16, (self.word_chars_size + 4), 1)),\n",
    "            nn.ConvTranspose2d(16, (self.word_chars_size + 4), kernel_size=(1, 1)),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d((self.word_chars_size + 4), 1, kernel_size=(1, char_embedding_dim), padding=(2, 0)),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "84896c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, encoder, context_size=2, hidden_dim=16):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.encoder = encoder\n",
    "        \n",
    "        self.cbow = nn.Sequential(\n",
    "            nn.Linear(context_size * self.encoder.word_embedding_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, self.encoder.char_num_embeddings * self.encoder.word_chars_size),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        size = len(x)\n",
    "        x = x.view(size * self.context_size, self.encoder.word_chars_size)\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(size, self.context_size * self.encoder.word_embedding_dim)\n",
    "        x = self.cbow(x)\n",
    "        x = x.view(size, self.encoder.word_chars_size, self.encoder.char_num_embeddings)\n",
    "        x = F.log_softmax(x, dim=2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "415cb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "lr = 0.00001\n",
    "char_num_embeddings = len(v1)  # size of the dictionary of embeddings\n",
    "char_embedding_dim = 8  # dimension of the char embedding\n",
    "word_embedding_dim = 2  # dimension of the word embedding\n",
    "word_chars_size = 6  # size of chars in a word\n",
    "context_size = 3  # size of words to use as context in CBOW\n",
    "\n",
    "encoder = Encoder(\n",
    "    char_num_embeddings=char_num_embeddings,\n",
    "    char_embedding_dim=char_embedding_dim,\n",
    "    word_embedding_dim=word_embedding_dim,\n",
    "    word_chars_size=word_chars_size,\n",
    "    ).to(device)\n",
    "encoder_opt = torch.optim.Adam(encoder.parameters(), lr=lr)\n",
    "\n",
    "decoder = Decoder(\n",
    "    char_num_embeddings=char_num_embeddings,\n",
    "    char_embedding_dim=char_embedding_dim,\n",
    "    word_embedding_dim=word_embedding_dim,\n",
    "    word_chars_size=word_chars_size,\n",
    "    ).to(device)\n",
    "decoder_opt = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "\n",
    "cbow = CBOW(encoder, context_size=context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "77cc849b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(torch.LongTensor([[1, 2, 4, 5, 9, 1], [1, 2, 4, 5, 10, 1], [1, 2, 4, 5, 10, 1]])).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "34b7f66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5152,  0.1101,  0.4665,  0.4608,  0.1533,  0.2767,  0.3929,\n",
       "           -0.0191],\n",
       "          [ 0.4220,  0.1719,  0.3538,  0.3417,  0.3096,  0.2442,  0.1459,\n",
       "            0.0635],\n",
       "          [ 0.3111,  0.1460,  0.3295,  0.3408,  0.1928,  0.2531,  0.3139,\n",
       "            0.1144],\n",
       "          [ 0.2529,  0.3060,  0.2864,  0.4245,  0.1493,  0.2880,  0.3163,\n",
       "            0.2132],\n",
       "          [ 0.5836,  0.2938,  0.3946,  0.3397,  0.1577,  0.2219,  0.3330,\n",
       "            0.2162],\n",
       "          [ 0.3986,  0.1081,  0.3163,  0.3311,  0.1863,  0.2213,  0.2560,\n",
       "            0.0717]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5179,  0.1070,  0.4661,  0.4555,  0.1559,  0.2735,  0.3882,\n",
       "           -0.0240],\n",
       "          [ 0.4167,  0.1704,  0.3509,  0.3439,  0.3050,  0.2455,  0.1493,\n",
       "            0.0658],\n",
       "          [ 0.3098,  0.1482,  0.3265,  0.3342,  0.1948,  0.2506,  0.3094,\n",
       "            0.1162],\n",
       "          [ 0.2455,  0.3063,  0.2836,  0.4191,  0.1477,  0.2869,  0.3182,\n",
       "            0.2140],\n",
       "          [ 0.5812,  0.2926,  0.3945,  0.3423,  0.1560,  0.2229,  0.3354,\n",
       "            0.2151],\n",
       "          [ 0.3911,  0.1108,  0.3164,  0.3270,  0.1843,  0.2220,  0.2592,\n",
       "            0.0700]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5179,  0.1070,  0.4661,  0.4555,  0.1559,  0.2735,  0.3882,\n",
       "           -0.0240],\n",
       "          [ 0.4167,  0.1704,  0.3509,  0.3439,  0.3050,  0.2455,  0.1493,\n",
       "            0.0658],\n",
       "          [ 0.3098,  0.1482,  0.3265,  0.3342,  0.1948,  0.2506,  0.3094,\n",
       "            0.1162],\n",
       "          [ 0.2455,  0.3063,  0.2836,  0.4191,  0.1477,  0.2869,  0.3182,\n",
       "            0.2140],\n",
       "          [ 0.5812,  0.2926,  0.3945,  0.3423,  0.1560,  0.2229,  0.3354,\n",
       "            0.2151],\n",
       "          [ 0.3911,  0.1108,  0.3164,  0.3270,  0.1843,  0.2220,  0.2592,\n",
       "            0.0700]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(encoder(torch.LongTensor([[1, 2, 4, 5, 9, 1], [1, 2, 4, 5, 10, 1], [1, 2, 4, 5, 10, 1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "63bd9635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.5013, -4.3151, -4.3870, -4.0942, -4.7874, -3.9470, -3.6737,\n",
       "          -4.8199, -4.8802, -4.4568, -3.8225, -4.4814, -3.6739, -4.2833,\n",
       "          -4.6093, -4.1806, -4.0067, -4.1466, -4.0712, -4.5833, -4.4849,\n",
       "          -4.9377, -3.8950, -3.9672, -4.3191, -4.6407, -4.5979, -4.7272,\n",
       "          -4.5984, -5.2834, -4.6484, -3.9636, -4.2710, -5.1401, -4.7937,\n",
       "          -3.8213, -4.4092, -4.3184, -4.9511, -4.6120, -4.2943, -3.6914,\n",
       "          -4.6399, -4.2426, -4.2834, -4.4456, -4.5493, -4.3814, -4.1899,\n",
       "          -4.3501, -5.6203, -4.1577, -3.8655, -4.5871, -4.6649, -4.5750,\n",
       "          -4.9073, -4.2124, -3.9721, -3.9324, -4.4779, -4.3933, -4.4485,\n",
       "          -4.3123, -4.6212, -4.6818, -4.1329, -3.9506, -4.0723, -4.9480,\n",
       "          -4.3912, -4.3138, -4.5372, -4.9883, -4.4857, -4.8501, -4.4514],\n",
       "         [-4.4666, -4.6144, -4.0790, -4.5302, -4.3440, -3.8733, -4.4915,\n",
       "          -4.2243, -4.3705, -4.3973, -4.8454, -4.5123, -4.6616, -4.5447,\n",
       "          -4.9126, -4.6122, -4.5586, -4.3699, -4.5147, -4.5009, -4.2517,\n",
       "          -3.6883, -4.5498, -4.0700, -5.0528, -4.5938, -3.8449, -4.5749,\n",
       "          -4.2896, -4.7476, -3.8331, -4.3547, -4.3098, -4.7549, -3.8685,\n",
       "          -5.1258, -4.2552, -4.4111, -4.8406, -4.3971, -4.3216, -4.7537,\n",
       "          -5.0415, -4.4635, -4.2253, -4.3321, -4.5752, -4.4659, -3.9842,\n",
       "          -4.2790, -4.1255, -4.6201, -4.2939, -4.4086, -4.5153, -4.9243,\n",
       "          -4.9285, -3.6472, -4.5905, -4.0413, -4.3046, -4.4833, -4.2667,\n",
       "          -4.3289, -4.0761, -3.7783, -4.1104, -4.2933, -4.5112, -4.3272,\n",
       "          -4.4313, -4.3959, -4.7430, -4.4316, -4.2754, -4.0663, -3.7892],\n",
       "         [-4.0790, -4.2918, -4.5253, -4.1145, -3.8518, -4.8055, -4.3659,\n",
       "          -4.1921, -4.4869, -4.0461, -4.3247, -4.9711, -5.2140, -4.6519,\n",
       "          -4.1330, -4.2409, -4.4143, -5.4376, -4.5537, -4.9261, -4.8644,\n",
       "          -4.7353, -4.3498, -4.4365, -4.0747, -4.2845, -4.5837, -4.2146,\n",
       "          -4.1785, -4.6051, -4.1469, -4.1176, -4.2169, -4.2041, -4.1314,\n",
       "          -4.3229, -4.8775, -4.6156, -4.1212, -4.8343, -4.0823, -4.6375,\n",
       "          -4.0067, -3.9548, -3.8885, -4.7659, -4.5738, -4.4317, -4.2322,\n",
       "          -4.5722, -4.7774, -4.5402, -5.0141, -4.2325, -4.3977, -3.8045,\n",
       "          -3.9210, -4.2038, -4.2685, -3.9786, -3.9009, -4.3989, -4.7697,\n",
       "          -4.6748, -4.8879, -4.2609, -4.1838, -4.2692, -4.5042, -4.0595,\n",
       "          -4.5581, -4.4408, -4.0421, -4.6931, -4.2241, -4.1283, -4.6286],\n",
       "         [-4.6259, -4.7468, -3.9208, -4.1098, -4.0217, -4.6832, -4.8302,\n",
       "          -4.0220, -4.3041, -4.1845, -4.2476, -3.7789, -4.4468, -4.6024,\n",
       "          -4.2376, -4.5136, -4.2113, -4.1427, -4.7156, -4.3560, -4.7002,\n",
       "          -4.5707, -4.3788, -4.1699, -4.6748, -4.1857, -3.5486, -4.3590,\n",
       "          -4.2100, -4.6218, -4.2601, -4.5030, -4.9183, -5.0301, -5.0782,\n",
       "          -4.5497, -4.8452, -4.7579, -4.4034, -4.6167, -4.5646, -4.9983,\n",
       "          -5.0868, -4.3337, -4.1294, -4.2634, -4.7678, -4.3720, -4.2069,\n",
       "          -4.9410, -4.6465, -3.9497, -4.6867, -3.9488, -4.7858, -4.2399,\n",
       "          -4.2739, -4.1826, -4.1914, -3.9890, -4.2368, -4.7727, -4.2600,\n",
       "          -4.2049, -4.2640, -3.7530, -4.2244, -4.6244, -4.0275, -4.1883,\n",
       "          -4.2276, -3.7827, -4.3197, -4.6930, -4.8074, -4.5372, -4.1515],\n",
       "         [-4.2367, -4.0337, -5.1735, -4.5451, -4.1524, -4.5662, -3.9337,\n",
       "          -4.7859, -4.3895, -4.4731, -3.9891, -3.9814, -4.9032, -4.4543,\n",
       "          -4.4877, -4.1285, -4.3438, -5.2516, -4.5351, -4.5352, -5.0207,\n",
       "          -4.1290, -4.6722, -3.8876, -4.4110, -4.9493, -4.2781, -4.2375,\n",
       "          -4.6220, -4.6476, -4.8112, -4.1164, -4.3247, -4.3930, -4.2117,\n",
       "          -4.2487, -4.1334, -3.9181, -4.0120, -4.6308, -4.2080, -4.1814,\n",
       "          -4.7628, -4.6430, -4.1893, -4.5258, -4.1863, -4.5916, -5.1296,\n",
       "          -4.3675, -4.4923, -4.4363, -4.5020, -4.5715, -4.6136, -4.8514,\n",
       "          -3.9787, -4.8428, -3.9253, -3.8855, -4.3305, -4.2648, -4.3198,\n",
       "          -4.1463, -4.0001, -4.6451, -4.1965, -4.2786, -4.9147, -4.3992,\n",
       "          -4.8370, -3.8430, -3.7601, -4.3056, -4.6638, -3.8472, -4.5088],\n",
       "         [-4.0599, -3.7470, -4.3583, -4.7308, -3.9927, -4.0610, -4.4929,\n",
       "          -4.6110, -4.4050, -4.3944, -4.6915, -4.1508, -4.0123, -4.7554,\n",
       "          -4.3172, -4.7232, -3.8643, -4.6697, -4.5485, -4.2604, -4.7401,\n",
       "          -3.8995, -5.0199, -4.5725, -4.7335, -4.6616, -4.1172, -4.1071,\n",
       "          -4.7639, -4.9160, -4.7130, -4.4725, -4.0912, -4.6542, -4.4884,\n",
       "          -4.2363, -4.4357, -4.2041, -4.1624, -4.3888, -4.1825, -4.4277,\n",
       "          -4.9131, -4.4734, -4.1076, -4.3859, -4.7959, -4.2746, -4.8677,\n",
       "          -4.6948, -3.9340, -3.8227, -4.3298, -4.7718, -4.6103, -4.5312,\n",
       "          -4.1177, -4.3928, -3.9796, -4.8003, -4.4781, -3.7456, -4.5857,\n",
       "          -4.7358, -4.4188, -4.1821, -4.3399, -4.8949, -4.6672, -4.1189,\n",
       "          -3.9681, -4.3164, -4.0200, -5.1883, -4.0642, -4.0421, -4.1241]],\n",
       "\n",
       "        [[-4.2905, -4.0907, -4.3575, -4.0601, -4.1495, -4.3717, -4.2121,\n",
       "          -4.3806, -4.6306, -4.5063, -4.2566, -4.6227, -4.4740, -3.8650,\n",
       "          -4.6649, -4.5619, -4.0450, -4.0591, -4.5154, -4.2535, -4.0791,\n",
       "          -4.3721, -4.3683, -4.4463, -4.5302, -4.2414, -4.6532, -4.6785,\n",
       "          -4.1945, -4.6088, -4.5649, -4.1332, -4.2822, -4.3669, -4.2037,\n",
       "          -3.9322, -4.3521, -4.6242, -4.6716, -4.2407, -4.0455, -4.3893,\n",
       "          -4.6595, -4.7513, -4.1780, -4.6097, -4.3427, -4.6098, -4.3620,\n",
       "          -4.3042, -4.8633, -3.9856, -4.3698, -4.3981, -4.7561, -4.4562,\n",
       "          -4.8110, -4.0378, -4.2711, -4.2288, -4.4763, -4.3918, -4.7359,\n",
       "          -3.9910, -4.5759, -4.2850, -4.1262, -4.2046, -4.1160, -4.3641,\n",
       "          -4.2976, -4.3563, -4.2233, -4.3489, -4.4969, -4.3994, -4.7086],\n",
       "         [-4.5867, -4.5152, -4.1699, -4.3286, -4.7747, -4.3492, -4.3211,\n",
       "          -4.2555, -4.2695, -4.1336, -4.4673, -4.4055, -4.1013, -4.4198,\n",
       "          -4.0962, -4.0224, -4.3798, -4.1945, -4.4948, -3.9873, -4.3549,\n",
       "          -4.3906, -4.5883, -4.3349, -4.4047, -4.4253, -3.9426, -4.3283,\n",
       "          -3.9937, -4.3493, -4.1689, -4.3168, -4.1160, -4.5573, -3.9437,\n",
       "          -4.6292, -4.2719, -4.2498, -4.7326, -4.4739, -4.4139, -4.4900,\n",
       "          -4.5634, -4.1990, -4.4515, -4.4854, -4.4347, -4.4961, -4.3723,\n",
       "          -4.6048, -4.0241, -4.6973, -4.1895, -4.3302, -4.4575, -4.5666,\n",
       "          -4.7174, -4.4045, -4.3980, -4.6742, -4.4984, -4.4635, -4.3395,\n",
       "          -4.2256, -4.2832, -4.0813, -4.0239, -4.7194, -4.5797, -4.1950,\n",
       "          -4.8532, -4.1714, -4.4275, -4.4018, -4.4203, -4.4716, -4.1364],\n",
       "         [-4.1370, -4.7432, -4.5361, -4.5475, -3.9888, -4.1995, -4.0218,\n",
       "          -4.6114, -4.3115, -4.7282, -4.3108, -4.2993, -4.6575, -4.3370,\n",
       "          -4.3377, -4.4493, -4.4761, -4.3461, -4.3624, -4.4955, -4.3012,\n",
       "          -4.5723, -3.9288, -4.5520, -4.2188, -4.1531, -4.2674, -4.4224,\n",
       "          -4.1100, -4.5124, -4.1726, -4.2240, -3.9888, -3.9540, -4.6117,\n",
       "          -4.3910, -4.4384, -4.4126, -4.3210, -4.4352, -4.5554, -4.4136,\n",
       "          -4.4956, -4.3075, -4.3604, -4.3844, -4.4180, -3.9692, -3.8579,\n",
       "          -4.7338, -4.1630, -4.6131, -4.6227, -4.1223, -4.7627, -4.5798,\n",
       "          -4.3247, -3.9726, -4.6948, -4.2035, -4.3103, -4.3398, -4.4471,\n",
       "          -4.5433, -4.5018, -4.1257, -4.6048, -4.4878, -4.5810, -4.1658,\n",
       "          -4.3862, -4.5489, -4.5525, -4.4718, -4.4117, -3.9137, -4.5325],\n",
       "         [-4.2512, -4.5935, -4.4840, -4.2882, -4.2933, -4.5741, -4.1959,\n",
       "          -4.1034, -4.0201, -4.5016, -4.4114, -3.8946, -4.5203, -4.6295,\n",
       "          -4.0456, -4.1650, -4.3686, -4.0451, -4.2287, -4.2704, -4.5089,\n",
       "          -4.4057, -4.3467, -4.2756, -4.4852, -4.3904, -4.0917, -4.0852,\n",
       "          -4.3387, -4.6187, -4.0398, -4.5609, -4.5320, -4.2500, -4.8745,\n",
       "          -4.3137, -4.3883, -4.6025, -4.2468, -4.5681, -4.2554, -4.4017,\n",
       "          -4.5963, -4.4539, -4.3300, -4.3748, -4.2370, -4.6260, -4.3863,\n",
       "          -4.4742, -4.5293, -4.1998, -4.2773, -4.6439, -4.2655, -4.3927,\n",
       "          -4.2217, -4.1326, -4.3457, -4.3999, -4.8465, -4.3693, -4.1177,\n",
       "          -4.2871, -4.6818, -4.3939, -4.5617, -4.0763, -4.1149, -4.1549,\n",
       "          -4.2359, -4.3552, -4.7178, -4.3145, -4.8059, -4.1187, -4.5663],\n",
       "         [-4.0745, -4.3746, -4.3428, -4.4779, -4.6183, -4.5715, -4.2459,\n",
       "          -4.4489, -4.4299, -4.2654, -4.3673, -4.1071, -4.4216, -4.1712,\n",
       "          -4.5776, -4.1887, -3.9341, -4.5573, -4.5319, -4.9291, -4.4392,\n",
       "          -4.4703, -4.4938, -4.0179, -4.3254, -4.3330, -4.0869, -4.3835,\n",
       "          -4.3637, -4.0689, -4.0745, -4.3913, -4.2162, -4.7183, -4.1588,\n",
       "          -4.2864, -4.5429, -4.1408, -4.4602, -4.2988, -4.3286, -4.4287,\n",
       "          -4.5120, -4.4452, -4.7367, -4.3209, -4.3467, -4.4180, -4.2681,\n",
       "          -4.5497, -4.5880, -4.0985, -4.7011, -4.2461, -4.5392, -4.4874,\n",
       "          -4.2046, -4.4339, -4.1158, -4.1211, -3.9288, -4.1696, -4.1817,\n",
       "          -4.3500, -4.4448, -4.4887, -4.1757, -4.7581, -4.5427, -4.4678,\n",
       "          -4.5725, -4.3870, -4.2274, -4.5401, -4.2296, -4.1563, -4.5807],\n",
       "         [-3.9607, -4.2906, -4.4324, -4.5975, -4.2208, -4.3314, -4.2939,\n",
       "          -4.2174, -4.4072, -4.5613, -4.1798, -4.2929, -4.3943, -4.1516,\n",
       "          -3.9906, -4.3238, -4.4638, -4.4795, -4.1852, -4.2825, -4.3840,\n",
       "          -4.3876, -4.3994, -4.2047, -4.3650, -4.7260, -4.5361, -4.4048,\n",
       "          -4.2917, -4.3359, -4.6774, -4.1894, -4.0101, -4.5723, -4.6999,\n",
       "          -4.1576, -4.4036, -4.5594, -4.2121, -4.4611, -4.1999, -4.1657,\n",
       "          -4.1691, -4.2584, -4.1990, -4.3577, -4.6417, -4.6527, -4.6868,\n",
       "          -4.6204, -4.7027, -3.9874, -4.4314, -4.6651, -4.6869, -4.3850,\n",
       "          -4.1055, -4.4951, -4.0571, -4.2444, -4.3230, -4.2835, -4.2020,\n",
       "          -4.6141, -4.5741, -4.4198, -4.3636, -4.1319, -4.6058, -4.4798,\n",
       "          -4.4185, -4.3199, -4.0869, -4.5291, -4.2223, -4.5727, -4.0625]]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow(torch.LongTensor([[[1, 2, 4, 5, 9, 1], [1, 2, 4, 5, 10, 1], [1, 2, 4, 5, 10, 1]], [[1, 2, 4, 5, 11, 1], [1, 2, 4, 5, 10, 1], [1, 2, 3, 5, 12, 1]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "33402244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['forty', 'When'], 'winters'), (['winters', 'forty'], 'shall'), (['shall', 'winters'], 'besiege')]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "tensor([80, 43])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 66\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m context, target \u001b[38;5;129;01min\u001b[39;00m ngrams:\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# into integer indices and wrap them in tensors)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     context_idxs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([word_to_ix[w] \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m context], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(context_idxs)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Step 2. Recall that torch *accumulates* gradients. Before passing in a\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# new instance, you need to zero out the gradients from the old\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# instance\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     model\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mException\u001b[0m: tensor([80, 43])"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "# We will use Shakespeare Sonnet 2\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "# we should tokenize the input, but we will ignore that for now\n",
    "# build a list of tuples.\n",
    "# Each tuple is ([ word_i-CONTEXT_SIZE, ..., word_i-1 ], target word)\n",
    "ngrams = [\n",
    "    (\n",
    "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
    "        test_sentence[i]\n",
    "    )\n",
    "    for i in range(CONTEXT_SIZE, len(test_sentence))\n",
    "]\n",
    "# Print the first 3, just so you can see what they look like.\n",
    "print(ngrams[:3])\n",
    "\n",
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in ngrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        raise Exception(context_idxs)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!\n",
    "\n",
    "# To get the embedding of a particular word, e.g. \"beauty\"\n",
    "print(model.embeddings.weight[word_to_ix[\"beauty\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e1c2bb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x30 and 20x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model(torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m45\u001b[39m]))\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 48\u001b[0m, in \u001b[0;36mNGramLanguageModeler.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m     47\u001b[0m     embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(inputs)\u001b[38;5;241m.\u001b[39mview((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 48\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(embeds))\n\u001b[0;32m     49\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(out)\n\u001b[0;32m     50\u001b[0m     log_probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x30 and 20x128)"
     ]
    }
   ],
   "source": [
    "model(torch.tensor([18, 28, 45]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b0cf05b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([96])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([word_to_ix[target]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5aeab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
